{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":792972,"sourceType":"datasetVersion","datasetId":1636},{"sourceId":7060243,"sourceType":"datasetVersion","datasetId":4064498}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# This file colntains the code to run **SVD** based movie recommendation model trained on the netflix prize dataset.","metadata":{}},{"cell_type":"code","source":"# Import the required libraries for reading the dataset\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reading the dataset that contains 15% of the original dataset\nratings_df = pd.read_csv('/kaggle/input/final-dataset/final_dataset.csv', encoding = \"ISO-8859-1\", header=0)\n\n# Looking at first 10 rows of data\nprint (ratings_df.head(10))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extracting the required columns into the dataset dataframe\ndataset = ratings_df[['CustomerID', 'Rating', 'MovieID']]\ndataset.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The following code is needed to correctly process the movie headers and merge them into a single column. The problem is occuring because the headers are a part of a csv file and the titles also have commas in them. Resolving this in the following code.","metadata":{}},{"cell_type":"code","source":"column_names = ['Movie_Id', 'YearOfRelease', 'Title', 'extra_col1', 'extra_col2', 'extracol3']\n\ndf_title = pd.read_csv('/kaggle/input/netflix-prize-data/movie_titles.csv', encoding = \"ISO-8859-1\", header = None, names = column_names)\n\n# Combine the last n columns into a new 'names' column\ndf_title['names'] = df_title.iloc[:, -4:].astype(str).apply(lambda row: ' '.join(row), axis=1)\n\n# Drop the last n columns if needed\ndf_title = df_title.iloc[:, :-4]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_title.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Installing the required scikit-surprise library\n!pip install scikit-surprise","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import required libraries to train and test the model\nfrom surprise import Reader, Dataset, SVD\nfrom surprise.model_selection import cross_validate","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The following is the **5-fold** and **10-fold** cross validation of the SVD model","metadata":{}},{"cell_type":"code","source":"reader = Reader()\n\n# Loading the required data into the data variable\ndata = Dataset.load_from_df(dataset[['CustomerID', 'MovieID', 'Rating']], reader)\n\n# Creating an instance of the SVD algorithm\nsvd = SVD()\n\n# Running the algoritghm for 5-fold cross validation.\nresult5 = cross_validate(svd, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Getting the RMSE values for 5-fold cross validation\nrmse_scores = result5['test_rmse']\n\n# Plotting the RMSE values\nplt.figure(figsize=(10, 8))\nplt.plot(range(1, len(rmse_scores) + 1), rmse_scores, marker='o', linestyle='-')\nplt.title('RMSE Values across Folds for 5 CV')\nplt.xlabel('Fold')\nplt.ylabel('RMSE')\nplt.grid(True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Running the above code for 10-fold cross validation\nreader = Reader()\n\n# Loading the required data into the data variable\ndata = Dataset.load_from_df(dataset[['CustomerID', 'MovieID', 'Rating']], reader)\n\n# Creating an instance of the SVD algorithm\nsvd = SVD()\n\n# Running the algoritghm for 10-fold cross validation.\nresult10 = cross_validate(svd, data, measures=['RMSE', 'MAE'], cv=10, verbose=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rmse_scores = result10['test_rmse']\n\n# Plot the RMSE values\nplt.figure(figsize=(10, 8))\nplt.plot(range(1, len(rmse_scores) + 1), rmse_scores, marker='o', linestyle='-')\nplt.title('RMSE Values across Folds for 10 CV')\nplt.xlabel('Fold')\nplt.ylabel('RMSE')\nplt.grid(True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The following is the code to train the model and generate recommendations for any given user","metadata":{}},{"cell_type":"code","source":"# Initialize a Reader object with the rating scale to be from 1 to 5\nreader = Reader(rating_scale=(1, 5))\n\n# Loading the required data into the data variable\ndata = Dataset.load_from_df(dataset[['CustomerID', 'MovieID', 'Rating']], reader)\n\nsvd = SVD()\n\n# Now that we are done verifying the working of the model, we can train the prediction model on the entire dataset\ntrainset = data.build_full_trainset()\nsvd.fit(trainset)\n\n# Function to get unrated movies for a user\ndef get_user_id_unrated(user_id):\n    # Get all movie IDs\n    all_movie_ids = dataset['MovieID'].unique()\n\n    # Get movies rated by the user\n    movies_rated_by_user = dataset[dataset['CustomerID'] == user_id]['MovieID'].tolist()\n\n    # Filter movies that the user hasn't rated yet\n    unrated_movies = [movie_id for movie_id in all_movie_ids if movie_id not in movies_rated_by_user]\n\n    return unrated_movies","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to get movie names from movie IDs\ndef get_movie_names_from_id(movie_ids):\n    movie_names = df_title.loc[df_title['Movie_Id'].isin(movie_ids), 'Title'].tolist()\n    return movie_names\n\n# user_id is the user for whom we want to recommend the movies\nuser_id = 71 \n\n# Since we dont want a movie that is already rated by the user to be recommended to them,\n# We get a list of movies not rated by them\nunrated_movies = get_user_id_unrated(user_id)\n\n# Using SVD model to predict the ratings of all the unrated movies\npredicted_ratings = [svd.predict(user_id, movie_id) for movie_id in unrated_movies]\n\n# The one user might like the most will be rated the highest in the prediction\npredicted_ratings.sort(key=lambda x: x.est, reverse=True)\n\n# Get the top 10 movie recommendations\ntop_n = 10 \nrecommended_movie_ids = [pred.iid for pred in predicted_ratings[:top_n]]\n\n\n# Get movie names corresponding to recommended movie IDs\nrecommended_movie = get_movie_names_from_id(recommended_movie_ids)\n\nprint(f\"Top 10 movie recommendations for user {user_id}:\")\nprint(recommended_movie)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking is any of the recommended movies has already been rated by the user\nuser_id = 71\n\n# Filter the dataframe to get all the MovieIDs with the given customerID\ncustomer_movies = dataset[dataset['CustomerID'] == user_id]['MovieID']\n\nif not dataset[(dataset['CustomerID'] == user_id) & (dataset['MovieID'].isin(recommended_movie_ids))].empty:\n    print(\"Some of the MovieIDs are already present for the given customerID.\")\n    print(dataset[(dataset['CustomerID'] == user_id) & (dataset['MovieID'].isin(recommended_movie_ids))])\nelse:\n    print(\"None of the above recommened movies are rated by the given customer.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}